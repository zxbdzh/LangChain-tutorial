{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f66eaf6025cc7c10",
   "metadata": {},
   "source": [
    "# 角度1出发：按照功能不同举例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c889f118a73ddab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 类型1：LLMs(非对话模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a92d7b8c007ba41e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:02:11.637007Z",
     "start_time": "2025-11-30T19:02:09.956664Z"
    }
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'timestamp': '2025-11-30T19:02:12.488+00:00', 'status': 404, 'error': 'Not Found', 'path': '/v4/completions'}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 10\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 无需重复赋值，ChatOpenAI 会自动读取环境变量\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# 核心代码\u001B[39;00m\n\u001B[0;32m      9\u001B[0m llm \u001B[38;5;241m=\u001B[39m OpenAI(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mglm-4.6\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m str_ \u001B[38;5;241m=\u001B[39m llm\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m写一首关于春天的诗\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;66;03m# 直接输入字符串\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(str_)\n",
      "File \u001B[1;32mF:\\env\\Python\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:392\u001B[0m, in \u001B[0;36mBaseLLM.invoke\u001B[1;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[0;32m    383\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    389\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m    390\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m--> 392\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_prompt(\n\u001B[0;32m    393\u001B[0m             [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_input(\u001B[38;5;28minput\u001B[39m)],\n\u001B[0;32m    394\u001B[0m             stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    395\u001B[0m             callbacks\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    396\u001B[0m             tags\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    397\u001B[0m             metadata\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    398\u001B[0m             run_name\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    399\u001B[0m             run_id\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    400\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    401\u001B[0m         )\n\u001B[0;32m    402\u001B[0m         \u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    403\u001B[0m         \u001B[38;5;241m.\u001B[39mtext\n\u001B[0;32m    404\u001B[0m     )\n",
      "File \u001B[1;32mF:\\env\\Python\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:791\u001B[0m, in \u001B[0;36mBaseLLM.generate_prompt\u001B[1;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    782\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[0;32m    783\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[0;32m    784\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    788\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    789\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    790\u001B[0m     prompt_strings \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_string() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m--> 791\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate(prompt_strings, stop\u001B[38;5;241m=\u001B[39mstop, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\env\\Python\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1002\u001B[0m, in \u001B[0;36mBaseLLM.generate\u001B[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[0;32m    987\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m get_llm_cache() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m    988\u001B[0m     run_managers \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    989\u001B[0m         callback_manager\u001B[38;5;241m.\u001B[39mon_llm_start(\n\u001B[0;32m    990\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_serialized,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1000\u001B[0m         )\n\u001B[0;32m   1001\u001B[0m     ]\n\u001B[1;32m-> 1002\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_helper(\n\u001B[0;32m   1003\u001B[0m         prompts,\n\u001B[0;32m   1004\u001B[0m         stop,\n\u001B[0;32m   1005\u001B[0m         run_managers,\n\u001B[0;32m   1006\u001B[0m         new_arg_supported\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m(new_arg_supported),\n\u001B[0;32m   1007\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1008\u001B[0m     )\n\u001B[0;32m   1009\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(missing_prompts) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1010\u001B[0m     run_managers \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   1011\u001B[0m         callback_managers[idx]\u001B[38;5;241m.\u001B[39mon_llm_start(\n\u001B[0;32m   1012\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_serialized,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1019\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m missing_prompt_idxs\n\u001B[0;32m   1020\u001B[0m     ]\n",
      "File \u001B[1;32mF:\\env\\Python\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:817\u001B[0m, in \u001B[0;36mBaseLLM._generate_helper\u001B[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001B[0m\n\u001B[0;32m    806\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_generate_helper\u001B[39m(\n\u001B[0;32m    807\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    808\u001B[0m     prompts: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    813\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    814\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    816\u001B[0m         output \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 817\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(\n\u001B[0;32m    818\u001B[0m                 prompts,\n\u001B[0;32m    819\u001B[0m                 stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    820\u001B[0m                 \u001B[38;5;66;03m# TODO: support multiple run managers\u001B[39;00m\n\u001B[0;32m    821\u001B[0m                 run_manager\u001B[38;5;241m=\u001B[39mrun_managers[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m run_managers \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    822\u001B[0m                 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    823\u001B[0m             )\n\u001B[0;32m    824\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    825\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(prompts, stop\u001B[38;5;241m=\u001B[39mstop)\n\u001B[0;32m    826\u001B[0m         )\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    828\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m run_manager \u001B[38;5;129;01min\u001B[39;00m run_managers:\n",
      "File \u001B[1;32mF:\\env\\Python\\anaconda3\\Lib\\site-packages\\langchain_openai\\llms\\base.py:343\u001B[0m, in \u001B[0;36mBaseOpenAI._generate\u001B[1;34m(self, prompts, stop, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    327\u001B[0m     choices\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m    328\u001B[0m         {\n\u001B[0;32m    329\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: generation\u001B[38;5;241m.\u001B[39mtext,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    340\u001B[0m         }\n\u001B[0;32m    341\u001B[0m     )\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 343\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(prompt\u001B[38;5;241m=\u001B[39m_prompts, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    345\u001B[0m         \u001B[38;5;66;03m# V1 client returns the response in an PyDantic object instead of\u001B[39;00m\n\u001B[0;32m    346\u001B[0m         \u001B[38;5;66;03m# dict. For the transition period, we deep convert it to dict.\u001B[39;00m\n\u001B[0;32m    347\u001B[0m         response \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mmodel_dump()\n",
      "File \u001B[1;32mF:\\env\\Python\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    284\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[1;32m--> 286\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\env\\Python\\anaconda3\\Lib\\site-packages\\openai\\resources\\completions.py:541\u001B[0m, in \u001B[0;36mCompletions.create\u001B[1;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    513\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    514\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    539\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[0;32m    540\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Completion \u001B[38;5;241m|\u001B[39m Stream[Completion]:\n\u001B[1;32m--> 541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[0;32m    542\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/completions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    543\u001B[0m         body\u001B[38;5;241m=\u001B[39mmaybe_transform(\n\u001B[0;32m    544\u001B[0m             {\n\u001B[0;32m    545\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: model,\n\u001B[0;32m    546\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m: prompt,\n\u001B[0;32m    547\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbest_of\u001B[39m\u001B[38;5;124m\"\u001B[39m: best_of,\n\u001B[0;32m    548\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mecho\u001B[39m\u001B[38;5;124m\"\u001B[39m: echo,\n\u001B[0;32m    549\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrequency_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: frequency_penalty,\n\u001B[0;32m    550\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogit_bias\u001B[39m\u001B[38;5;124m\"\u001B[39m: logit_bias,\n\u001B[0;32m    551\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: logprobs,\n\u001B[0;32m    552\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: max_tokens,\n\u001B[0;32m    553\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m\"\u001B[39m: n,\n\u001B[0;32m    554\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpresence_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: presence_penalty,\n\u001B[0;32m    555\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m: seed,\n\u001B[0;32m    556\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop\u001B[39m\u001B[38;5;124m\"\u001B[39m: stop,\n\u001B[0;32m    557\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream,\n\u001B[0;32m    558\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream_options\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream_options,\n\u001B[0;32m    559\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msuffix\u001B[39m\u001B[38;5;124m\"\u001B[39m: suffix,\n\u001B[0;32m    560\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m: temperature,\n\u001B[0;32m    561\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_p\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_p,\n\u001B[0;32m    562\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m: user,\n\u001B[0;32m    563\u001B[0m             },\n\u001B[0;32m    564\u001B[0m             completion_create_params\u001B[38;5;241m.\u001B[39mCompletionCreateParamsStreaming\n\u001B[0;32m    565\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m stream\n\u001B[0;32m    566\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m completion_create_params\u001B[38;5;241m.\u001B[39mCompletionCreateParamsNonStreaming,\n\u001B[0;32m    567\u001B[0m         ),\n\u001B[0;32m    568\u001B[0m         options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[0;32m    569\u001B[0m             extra_headers\u001B[38;5;241m=\u001B[39mextra_headers, extra_query\u001B[38;5;241m=\u001B[39mextra_query, extra_body\u001B[38;5;241m=\u001B[39mextra_body, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[0;32m    570\u001B[0m         ),\n\u001B[0;32m    571\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mCompletion,\n\u001B[0;32m    572\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    573\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mStream[Completion],\n\u001B[0;32m    574\u001B[0m     )\n",
      "File \u001B[1;32mF:\\env\\Python\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1259\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1246\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1247\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1254\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1255\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1256\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1257\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1258\u001B[0m     )\n\u001B[1;32m-> 1259\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[1;32mF:\\env\\Python\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1047\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1044\u001B[0m             err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m   1046\u001B[0m         log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1047\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1049\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m   1051\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcould not resolve response (should never happen)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mNotFoundError\u001B[0m: Error code: 404 - {'timestamp': '2025-11-30T19:02:12.488+00:00', 'status': 404, 'error': 'Not Found', 'path': '/v4/completions'}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "# 无需重复赋值，ChatOpenAI 会自动读取环境变量\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# 核心代码\n",
    "llm = ChatOpenAI(model=\"glm-4.6\")\n",
    "str_ = llm.invoke(\"写一首关于春天的诗\")  # 直接输入字符串\n",
    "print(str_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e547dcb03f1b9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 类型2：Chat Models(对话模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23e979d1824e507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:09:55.245822Z",
     "start_time": "2025-11-30T19:09:30.720397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "\n",
      "小明你好！我也很高兴认识你。\n",
      "\n",
      "我是zxb，很高兴能为你服务。有什么想问的或者需要帮忙的，随时都可以告诉我。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 核心代码\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL\"))\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"我是人工智能助手，我叫zxb\"),\n",
    "    HumanMessage(content=\"你好，我是小明，很高兴认识你\")\n",
    "]\n",
    "response = chat_model.invoke(messages)  # 输入消息列表\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af193e6be9fd7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 类型3：Embedding Model(嵌入模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b06fbed6ca946e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T22:53:58.884656Z",
     "start_time": "2025-11-30T22:53:56.851553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00062399893, 0.009990169, -0.022924809, 0.013213004, -0.017357532, 0.0008861249, -0.025559986, 0.0143759465, 0.024397044, 0.025955882, 0.022541285, -0.0014567708, 0.01647914, -0.04228656, -0.007868418, -0.0296674, -0.038649272, -0.010584012, -0.012779993, 0.0041816435, 0.03409648, 0.01821118, -0.023691855, 0.011672724, 0.011085067, -0.007998321, 0.03340366, 0.023753714, 0.005486861, -0.012965569, 0.021180395, 0.057949167, -0.02228148, 0.013769732, 0.010447923, 0.0044878437, -0.014227485, 0.022627888, 0.017555479, -0.028059075, 0.0003454418, 0.038154405, -0.0022671188, -0.030681882, 0.014487292, 0.0007500359, -0.066609375, -0.0019207106, -0.004896111, -0.0015356406, 0.021019563, -0.0042187585, 0.033007767, -0.013151146, -0.003396039, 0.0031857195, -0.0093282815, 0.0183349, -0.013188261, 0.014524407, -0.0039960677, -0.00610854, 0.017035868, 0.010188117, 0.0130769145, 0.022627888, -0.015415171, -0.017679198, -0.016305935, 0.017877145, -0.0022269108, 0.0035383138, -0.0021434017, 0.01920092, 0.042113356, 0.029494196, -0.014153255, -0.0121304775, 0.009996355, 0.029123044, 0.007893162, 0.013299606, 0.017629711, -0.0035878005, 0.018495731, 0.016825547, 0.023246475, 0.021229882, 0.021081422, -0.026772415, 0.028133307, 0.008684952, 0.018842138, 0.0010082957, 0.031349953, -0.020104056, -0.04520629, 0.020549437, 0.0020243237, 0.027044594, 0.011289201, -0.015588375, 0.00852412, -0.027762154, 0.031646878, 0.0059600794, -0.0039032798, 0.0052239615, 0.012316054, -0.037807997, -0.03783274, -0.006099261, -0.00784986, -0.0033836672, 0.02320936, -0.027465232, 0.01683792, -0.0017057518, -0.0038012129, -0.005208497, -0.0048156944, -0.00018712236, -0.010305648, 0.009847894, -0.01749362, -0.011190226, -0.034566604, -0.026450751, -0.034418143, 0.0011675816, 0.0062570004, -0.01114074, 0.030929316, -4.711888e-05, -0.0017088447, -0.015279082, -0.009711805, 0.018829767, 0.012483072, 0.006021938, 0.0014111501, 0.03919363, 0.008289057, -0.01383159, -0.004661048, -0.104318395, 0.005415723, -0.006377625, 0.0052301474, -0.010936606, -0.0137078725, -0.0025779584, -0.00017939003, -0.016070873, -0.014450177, 0.0088829, -0.012977941, 0.00569718, -0.010726287, -0.019435981, 0.0011474777, -0.0008405042, 0.0003732782, 0.0006479692, 0.0068972376, -0.03303251, -0.007447779, -0.0025392969, -0.012940826, 0.004376498, 0.01085619, -0.033354174, 0.015452286, -0.05596969, 0.015130621, 0.0011853661, -0.013064543, 0.028083818, -0.05015498, -0.005292006, -0.0023954755, 0.00960046, 0.01870605, 0.016615229, 0.0059600794, -0.021539176, -0.017889516, -0.012328425, 0.01221708, 0.015576003, -0.0025238323, 0.018112207, 0.004964155, -0.0135470405, 0.015464658, -0.014709983, -0.00023564273, 0.008505562, -0.022120647, 0.023060897, 0.012309868, -0.015254338, 0.031844825, 0.01013863, -0.015934784, -0.0069776536, -0.011988203, 0.007905534, -0.006294116, 0.004292989, -0.033131484, -0.0045280517, -0.0006846977, 0.01193253, 0.008425145, -0.017642083, 0.005013642, -0.026129086, 0.0005810845, -0.03389853, -0.017468877, -0.025782678, -0.010311834, -0.0056105778, 0.0016995659, -0.024087751, -0.004194015, -0.008375659, -0.095905624, 0.032834563, -0.033849042, 0.013843962, 0.014821328, -0.08798772, -0.004234223, 0.009464371, -0.02049995, -0.034962498, 0.005743574, 0.011060324, -0.013967679, 0.017543107, 0.012878967, 0.028727148, -0.009489114, 0.013410951, 0.029568426, -0.0077137714, 0.0039682314, 0.013868705, -0.019893736, -0.030211756, -0.004067205, -0.020104056, -0.027960101, 0.025559986, 0.018446244, -0.025559986, -0.004200201, 0.02150206, 0.00019891416, 0.008152967, -0.009971611, -0.000785218, -0.012303682, 0.0332552, -0.006291023, -0.011128368, -0.020116428, -0.042608224, 0.033279944, -0.00060080196, 0.025337296, 0.039663754, 0.009117963, 0.00047128546, -0.011332502, -0.008023065, -0.03038496, 0.06433298, -0.00013077301, 0.0154027995, 0.0040393686, 0.021811353, -0.01591004, 0.011487148, 0.0065941303, -0.011196412, 0.015947156, -0.00031412588, 0.006996211, 0.017258558, 0.006427112, -0.013336721, -0.007447779, 0.019572072, 0.019757647, -0.00048017764, 0.034591347, -0.0010098421, -0.0054095373, 0.013188261, -0.01813695, -0.024545506, 0.061314277, -0.010447923, -0.038030688, -0.011047952, -0.014239857, 0.0010253069, -0.0050785937, -0.008159153, -0.0022532006, 0.018817395, 0.0031795336, 0.020932961, 0.00705807, -0.0017150305, -0.007379735, -0.017134842, -0.00067541894, -0.0022918624, -0.023964034, 0.017604966, -0.0015882204, 0.012891339, 0.0060714246, -0.005799247, -0.022677375, -4.7433005e-05, 0.017171957, -0.03167162, 0.025906395, 0.008635465, -0.012841852, -0.0030821064, -0.041346308, -0.0015000718, 0.0047290926, 0.01948547, 0.03132521, 0.007911719, 0.004518773, -0.01791426, -0.016231705, -0.017864773, -0.021254625, 0.0066683604, 0.0030851993, -0.018075092, -0.042484507, -0.019881364, -0.0043517547, -0.007973578, 0.0145738935, 0.011165483, 0.030558163, -0.007967392, 0.059285313, -0.02092059, 0.009767478, -6.364673e-05, -0.0046826983, 0.013126401, -0.0012170686, 0.041346308, 0.01555126, 0.040950414, 4.678059e-05, -0.0009765931, -0.0009000431, -0.022702118, -0.022405196, -0.085810296, -0.0071199285, -0.04122259, 0.026327034, -0.018903999, 0.018112207, -0.0017459599, -0.027094081, -0.011722211, 0.006606502, 0.003791934, -0.016714202, 0.0113386875, -0.037956458, -0.011351059, -0.014586265, 0.012384098, -0.002715594, 0.016021386, -0.018854512, 0.019918479, -0.02106905, -0.034863524, 0.004970341, -0.007726143, -0.17538159, 0.025461012, -0.029766373, 0.0019238035, 0.0052332403, -0.016009014, 0.012662462, 0.031127263, -0.008214827, -0.02099482, 0.009223122, -0.031795338, 0.020326747, -0.010887119, 0.016936893, -0.02823228, 0.047358967, 0.036521338, 0.0074848942, -0.007181787, -0.025362039, 0.03711518, -0.026054855, -0.026574468, -0.014747098, 0.020227773, -0.006117819, -0.035853263, 0.0018944206, 0.009303538, -0.01906483, -0.010961349, 0.009711805, -0.009742735, 0.01756785, 0.032983024, 0.0028424042, 0.0057652243, -0.0023552673, -0.003204277, 0.018681306, -0.0035475926, 0.013324349, 0.008431331, 0.014611009, 0.0022965018, 0.017134842, 0.0059508006, -0.037783254, -0.013175889, 0.0020923682, -0.024285698, -0.02250417, -0.0049022967, -0.00557037, 0.02902407, -0.0005145865, 0.016070873, -0.00040324096, -0.025040375, 0.017629711, -0.030434446, -0.0053074704, -0.0010214406, 0.2921707, 0.009687061, 0.01942361, 0.017976118, 0.005214683, -0.013435694, 0.013126401, 0.0149697885, -0.018730793, 0.007862232, 0.021106165, -0.018112207, -0.0009564891, 0.012693391, -0.009786036, 0.03956478, 0.020165915, 0.008790111, -0.012878967, -0.002935192, -0.018755537, -0.013274862, 0.010701544, 0.013064543, -0.009117963, -0.0073982924, 0.012619161, -0.011685096, -0.012173778, -0.0135470405, -0.010379879, -0.0027217797, -0.0006576346, -0.01920092, -0.00916745, -0.024706338, 0.049759082, -0.037164666, -0.030830342, -0.0027573486, 0.009186007, -0.013744988, -0.013015056, -0.0076086116, -0.0010338124, 0.017802915, 0.0064394837, -0.008004507, -0.015378056, 0.0094458135, -0.013460439, 0.018582333, -0.0012936186, -0.014215114, -8.147942e-05, -0.013744988, 0.008907643, 0.02006694, 0.021687636, -0.0045651672, -0.018025605, -0.014388318, -0.033725325, 0.0030991174, -0.0142646, 0.036521338, 0.013868705, 0.0013817672, 0.026698185, -0.017110098, 0.011029394, -0.010342763, 0.01985662, 0.027910614, 0.040653493, 0.015947156, 0.0022934088, 0.02035149, 0.020475207, -0.03538314, 0.012557303, -0.013225376, 0.010540711, 0.036521338, 0.0003034939, -0.0024526948, 0.007763258, -0.007274575, -0.0005192259, -0.013138774, 0.016503884, -0.020042196, 0.017035868, -0.030285986, 0.01734516, 0.010837632, 0.0045033083, -0.037956458, 0.016367793, 0.011833556, -0.005069315, -0.012439771, 0.039540038, 0.009656132, 0.009730362, 0.037733767, -0.01626882, 0.009656132, -0.013683129, -0.022553656, -0.001942361, -0.006779706, -0.01878028, -0.02229385, -0.032562383, -0.017456505, -0.016281191, -0.0030001437, 0.03446763, -0.008901457, -0.02163815, -0.012210894, 0.018755537, -0.0023382562, 0.035333652, 0.006052867, 0.0031362327, -0.014945045, 0.0058208974, -0.03597698, 0.0135470405, 0.008604536, -0.0028810657, -0.00026444564, -0.042830918, 0.011072695, -0.022961924, 0.04493411, 0.038649272, -0.030137526, -0.0030140618, -0.030483933, -0.016738946, 0.0030403517, 0.0034207823, -0.0027712667, 0.009625203, -0.025312552, -0.006402368, -0.021106165, 0.0076766564, 0.01612036, 0.036521338, 0.03483878, -0.07522009, 0.01970816, 0.026524981, 0.03087983, 0.014004794, -0.008152967, -0.0095633445, -0.019967966, 0.012878967, -0.02823228, 0.0062106065, 0.01612036, 0.005740481, -0.01203769, 0.029123044, -0.022491798, 0.021724751, -0.018767908, -0.0068972376, -0.00053469057, 0.017060611, 0.007973578, 0.012804736, 0.007812745, -0.025733192, -0.016677087, 0.0013864066, 0.0027434304, 0.0017351346, 0.023988778, -0.009451999, -0.02114328, 0.0009124148, 0.0067549627, 0.02328359, 0.032908794, -0.0015820345, -0.006062146, 0.027366258, -0.0069776536, 0.012000575, 0.018755537, 0.01863182, 0.017778171, -0.003795027, 0.036150184, 0.026327034, -0.012272753, 0.0048218803, 0.018322527, -0.010614941, -0.019337008, 0.026401265, 0.01454915, -0.004614654, 0.025881652, -0.001175314, -0.01057164, 0.012192336, -0.004784765, 0.006371439, 0.025856908, 0.0034145964, 0.015328569, 0.0037857483, -0.01948547, -0.00777563, -0.019398866, 0.020636039, 0.07957494, -0.007051884, -0.00462084, 0.0029166345, 0.0013384662, 0.007856046, 0.0032908793, -0.0020413348, -0.0035599642, 0.031844825, 0.13519822, 0.00047553823, 0.013621271, 0.009965425, -0.03397276, 0.028182793, -0.01749362, -0.032512896, 0.016961636, -0.0160585, 0.008703509, -0.0044538216, -0.014870815, -0.008703509, -0.01798849, -0.04008439, 0.031201493, -0.011060324, -0.0047723935, -0.04149477, 0.005146638, 0.009421069, 0.03038496, -0.01555126, -0.029914834, -0.0029320992, 0.0027465234, 0.001696473, -0.021266997, 0.023976406, -0.030607652, -0.011579935, -0.01064587, -0.035506856, -0.016021386, -0.042608224, 0.020302003, -0.017976118, 0.021922698, 0.015217223, -0.0097612925, 0.018198809, 0.02084636, 0.015588375, -0.004070298, 0.03295828, 0.004153807, -0.037065692, 0.00045466094, 0.0013338268, 0.001142065, 0.0028671476, -0.030756112, 0.01454915, -0.03676877, -0.026896134, 0.003791934, -0.0063961823, -0.014202742, -0.004713628, 0.015241967, 0.004933226, 0.0017382276, 0.021724751, -0.034269683, 0.008363287, 0.013175889, 0.010144816, -0.03288405, 0.020537065, -0.023988778, -0.02286295, -0.010627313, 0.013509925, -0.020091685, 0.0030372587, 0.0070395125, 0.049907543, 0.016070873, -0.0020011268, -0.004973434, -0.016281191, -0.0007627942, 0.023741342, -0.0067116613, 0.008227198, 0.011412918, -0.001265009, -0.021464946, -0.0296674, -0.009142706, -0.0015333209, -0.030582907, -0.006046681, 0.004023904, -0.016182218, -0.004292989, -0.025461012, 0.021885583, -0.022751605, -0.0057930606, -0.0005783782, -0.016454397, 0.091699235, 0.004698163, -0.033304688, -0.036941975, 0.0014521314, 0.015241967, 0.006643617, 0.014301715, -0.017456505, -0.02278872, -0.0033867601, -0.03919363, 0.026129086, 0.023914548, -0.010553082, -0.008734439, -0.008845785, 0.025362039, 0.0054064444, -0.017283302, 0.02515172, -0.0029831326, 0.0024155795, -0.009971611, -0.034566604, -0.0033094368, -0.008851971, -0.019386495, 0.033601608, -0.017011125, 0.0021588663, -0.009396326, 0.0020769036, 0.004797137, 0.0055796485, 0.019361751, -0.01913906, 0.019497842, -0.014276972, -0.006377625, -0.017357532, 0.0043270113, -0.00022462416, -0.018941114, 0.022046417, 0.019473098, -0.0054837675, -0.006158027, -0.034145966, -0.010169559, -0.010491224, -0.027415745, 0.0113386875, 0.014709983, 0.010936606, 0.016788432, 0.0078313025, -0.0039558597, -0.0072250883, 0.011301572, -0.0007871511, 0.041049387, 6.152034e-05, 0.01761734, -0.013299606, -0.0029027164, -0.004617747, -0.0037146108, -0.022182506, 0.022479426, -0.03545737, -0.011641795, 0.014202742, -0.049684852, -0.04221233, 0.04701256, -0.0039063725, 0.024087751, 0.003949674, 0.027762154, -0.009322096, 0.009204565, 0.0077941874, -0.008876714, 0.015514145, -0.0033187156, -0.010614941, -0.0007589281, -0.008214827, -0.016281191, -0.023964034, 0.0086973235, 0.019448353, -0.009179821, 0.021328857, -0.006575573, 0.021403087, 0.005833269, 0.0026073414, -0.024100123, -0.0057219234, -0.0054033515, -0.0057899677, -0.020190658, 0.0003319102, -0.0055734627, -0.0067549627, -0.018396758, 0.02084636, 0.0018573054, 0.007583868, 0.0021604127, 1.1616616e-05, -0.010416994, 0.007973578, -0.0055456264, 0.010825261, -0.0040888553, 0.019609187, -0.01704824, 0.007868418, -0.017889516, -0.016503884, 0.011134554, -0.036917232, -0.0044909366, 0.0035908935, -0.0063899965, -0.005341493, -0.012000575, 0.005254891, 0.02386506, 0.020883474, -0.02121751, 0.009322096, 0.016442025, -0.0019686508, 0.006021938, 0.037733767, 0.013992422, 0.013967679, -0.029791117, -0.011629423, 0.009532415, 0.0053538647, 0.036001723, 0.00020432679, 0.022900065, 0.01511825, 0.015291453, -0.02129174, -0.062551446, -0.008635465, 0.020908218, 0.025040375, -0.027465232, -0.012272753, -0.010862376, -0.00852412, 0.008783925, -0.021675264, 0.03654608, -0.021823725, -0.0036805887, -0.017308045, 0.011431475, -0.0034115035, -0.01870605, -0.015291453, 0.008431331, 0.0014397596, 0.2290254, 0.007911719, 0.04807653, 0.005276541, -0.02035149, -0.02815805, -0.0021434017, -0.038451325, 0.02236808, 0.011765512, -0.007590054, 0.014363574, 0.0068539362, 0.009990169, -0.010429366, 0.02358051, -0.035086215, 0.001221708, -0.003389853, -0.014450177, 0.0020676248, -0.00094334414, 0.014499663, -0.048645627, 0.016083244, 0.005468303, 0.0051775677, 0.015823439, 0.006823007, 0.0062229782, -0.0058487337, -0.02350628, 0.0047043487, -0.0026862111, 0.0058580125, -0.046740383, -0.005248705, 0.0060435883, -0.030137526, -0.014029537, 0.017679198, -0.004834252, 0.0067549627, -0.004964155, -0.021130908, 0.00049718877, 0.01239647, -0.0032228348, -0.018050348, 0.0022934088, 0.022467054, -0.006792078, 0.002576412, 0.016639972, 0.01583581, -0.007633355, 0.009043732, -0.010188117, 0.011487148, -0.012804736, 0.032933537, 0.03949055, -0.0054466524, -0.007905534, 0.038674016, 0.003881629, 0.009482929, -0.04844768, 0.06472887, 0.01475947, -0.024966143, -0.0070209545, 0.0068353787, 0.013213004, -0.0115366345, 0.0053105634, -0.018458616, -0.023493908, 0.059829667, 0.015229595, -0.013299606, 0.015922412, 0.023902176, -0.014709983, 0.0055889273, -0.021749495, -0.0055765556, 0.029147787, -0.007379735, -0.011462404, -0.006334324, 0.0026521888, -0.021823725, 0.0033805743, 0.012248009, -0.011746954, -0.005381701, -0.020957705, -0.012173778, 0.03231495, 0.0044507287, -0.03483878, -0.034121223, 0.016924521, 0.014252229, 0.024038265, -0.02981586, 0.014598637, -0.024063008, -0.011060324, 0.016182218, -0.024025893, 0.0189906, -0.0047383714, 0.041890666, -0.0030233406, 0.005425002, 0.0143388305, 0.025201207, 0.010800517, 0.00992831, 0.00018586585, 0.012569674, 0.022974296, -0.002417126, -0.010528339, -0.01390582, 0.014103768, -0.0011930984, 0.00451568, 0.015749207, 0.020363862, -0.033131484, -0.0041847364, -0.006557015, -0.01555126, -0.0005385567, 0.019040087, 0.028083818, 0.0021928884, 0.029222017, 0.003167162, 0.008053994, -0.0039001866, 0.0015279083, 0.009056103, -0.02315987, -0.007998321, 0.0012333065, -0.017518364, 0.0020939147, -0.0067240335, -0.024953771, -0.0012016039, 0.007961206, 0.026648698, -0.00723746, 0.0027511627, 0.013101658, -0.017072983, 0.0041352496, 0.024285698, 0.02830651, 0.03446763, -0.00695291, -0.0073549915, -0.034294426, 0.006717847, -0.010682986, -0.005567277, -0.0379812, -0.02887561, -0.00343934, 0.013213004, -0.017951375, 0.031498414, -0.018755537, 0.008703509, 0.0069343527, 0.00992831, -0.020252516, -0.00085519557, -0.007843674, 0.031547904, -0.0106768, 0.00046007358, -0.01182737, 0.0030712811, 0.011276828, 0.0021975278, -0.010410808, -0.021019563, 0.0055518122, -0.0024743453, 0.034566604, 0.035556342, -0.040529776, 0.0150069045, -0.036447104, -0.0083138, 0.0028625082, -0.012254195, 0.00041251976, 0.023320705, -0.017951375, 0.001344652, -0.0054002586, 0.0166276, 0.018223552, 0.005786875, -0.013497554, -0.004376498, -0.0025795049, -0.015526516, 0.015650233, 0.008338544, 0.036298644, 0.015142993, 0.028727148, -0.0027341514, 0.0037146108, 0.013955307, 0.027143568, -0.00096267497, -0.028751893, 0.013336721, 0.02815805, -0.020722643, 0.013683129, -0.0053569577, 0.019337008, 0.0152048515, 0.00073689094, 0.009656132, -0.003841421, -0.0020428812, 0.010194303, 0.005607485, -0.0037424471, 0.00095107645, 0.020091685, -0.010621127, 0.0021372158, -0.008944758, 0.017889516, 0.0009472103, -0.029494196, -0.033378918, -0.0024186724, -0.025386782, -0.0062693725, -0.026475495, -0.010256161, -0.008357101, -0.00040865358, 0.02114328, -0.020561809, -0.0036774958, 0.0065941303, 0.002081543, 0.00021534537, -0.028553944, 0.00910559, -0.022751605, 0.030483933, -0.004509494, -0.04258348, -0.008221013, 0.001783075, -0.033205714, -0.0047105346, -0.0057683173, -0.030558163, 0.026920877, -0.0026707465, -0.000979686, 0.03498724, -0.008480818, 0.015167736, 0.021922698, -0.018569961, -0.017703941, 0.0071570436, -0.009377768, -0.0011637155, -0.0091303345, 0.016454397, 0.019460725, -0.025040375, -0.0073549915, 0.01519248, -0.0053322143, 0.0149697885, -0.03718941, 0.008709695, 0.021106165, -0.027984845, -0.022157762, -0.0068044495, 0.034492373, 0.009612831, -0.00060080196, -0.01741939, -0.0057219234, -0.009278795, -0.019918479, -0.008969502, 0.00125805, 0.014388318, -0.010924234, 0.026549725, 0.0026800253, -0.026129086, 0.023716599, 0.028578687, 0.038896706, 0.001460637, -0.01064587, -0.0020274166, -0.0031949983, -0.013782104, -0.010534525, -0.0026166202, -0.010806703, -0.00042489148, -0.023135127, 0.03424494, -0.039960675, 0.009699433, 0.01490793, -0.046740383, 0.026722929, 0.002417126, -0.0025934232, 0.0006692331, -0.00859835, -0.013423323, -0.018792652, 0.020796873, 0.020339118, -0.027440488, -0.045057826, 0.011159297, 0.012693391, 0.021625778, -0.0006951364, -0.037016205, -0.031349953, -0.018928742, -0.017407019, -0.00616112, 0.0020892753, -0.01000254, -0.005208497, 0.038154405, -0.009037546, -0.013015056, 0.0044167065, -0.01013863, -0.0011930984, -0.00027411105, 0.011913973, -0.00992831, -0.0030960245, 0.02350628, -0.0036651238, 0.012056247, 0.0055796485, -0.008078737, -0.019906107, -0.0014614102, -0.0030527236, -0.007763258, 0.021056678, 0.003658938, 0.0062724655, 0.015316198, 0.0094086975, 0.022442311, -0.0071632294, 0.0010871654, 0.00078289834, -0.01193253, -0.0013059904, 0.01827304, -0.017790543, 0.0037269825, 0.013509925, 0.020895846, -0.033576865, 0.01677606, 0.0026800253, -0.013460439, -0.042954635, 0.01999271, -0.006148748, -0.019225663, 0.025658961, 0.0057095517, -0.007410664, -0.005292006, 0.04664141, 0.0073364335, -0.000418319, 0.0051775677, -0.09521281, -0.0017985398, 0.04406809, 0.020153543, -0.013881077, 0.009266423, 0.0062508145, 0.016219333, 0.0077137714, 0.0011544367, 0.0048589953, 0.0030465375, 0.029048814, 0.011691282, 0.027366258, 0.00367131, 0.023308333, 0.0057528527, 0.012718135, 0.023555767, 0.02701985, -0.0026042485, 0.01475947, 0.033131484, 0.0011072695, -0.052901503, -0.0062662796, -0.0039929748, -0.00038700306, -0.00903136, 0.015897669, -0.028652918, 0.02235571, -0.01085619, -0.0016129639, 0.01447492, 0.044191808, -0.025250694, -0.0041012275, -0.019163804, 0.015167736, 0.010225232, 0.018124579, 0.0059941015, 0.011592308, 0.0009866452, 0.004524959, 0.0059260568, -0.0005536348, 0.016961636, -0.016813176, -0.024285698, 0.014586265, -0.01569972, -0.0018279225, 0.010082957, 0.011091253, -0.005783782, 0.016503884, -0.00088225876, 0.0002066465, 0.0053012846, 0.0005787648, 0.0037733766, -0.06735168, -0.0032321136, -0.013052171, 0.037090436, 0.021811353, 0.0043146396, -0.007818931, -0.0036744028, 0.06680732, 0.028331254, -0.0040826695, -0.019262778, -0.016540999, 0.0062693725, -0.042484507, 0.01157375, 0.00054976856, 0.0008667941, 0.0040826695, -0.028999327, 0.023246475, 0.021811353, 0.0074725226, 0.016949264, 0.028479714, -0.011617051, 0.011864485, 0.019460725, 0.0468641, 0.0034733622, -0.005700273, -0.016788432, 0.0077137714, 0.003143965, -0.006046681, 0.0049146684, -0.0031949983, -0.0074354075, 0.040826697, -0.010720101, -0.001162169, 0.008233384, 0.0017289488, -0.013299606, -0.0540397, 0.009711805, -0.006408554, -0.0022810372, 0.015390428, 0.011833556, -0.031275723, -0.02350628, 0.012346983, 0.02530018, 0.010843818, -0.0137078725, -0.0038940008, 0.015427543, 0.0012565035, -0.012841852, 0.0055734627, 0.0007550619, -0.011901601, -0.0035444996, 0.008258128, 0.004930133, -0.008016879, 0.0011467044, 0.011233527, -0.024496019, -0.03182008, -0.006328138, 0.00539098, 0.0351357, -0.009359211, 0.00034234885, -0.010219046, 0.004484751, 0.012328425, 0.017716313, 0.0024480554, -0.0055456264, -0.024421789, -0.0058085257, -0.003201184, 0.043152582, 0.009705619, 0.008159153, -0.010528339, -0.0066559887, -0.0062229782, 0.009464371, -0.03367584, -0.00605596, -0.04429078, 0.041049387, 0.016070873, -0.030731369, 0.0039620455, 0.013497554, -0.011301572, 0.014388318, -0.00379812, -0.027613694, -0.009006617, -0.004268246, -0.0014467187, -0.024322813, 0.0092478655, -0.008548863, -0.013138774, -0.008128224, 0.02959317, 0.028331254, 0.0028671476, -0.0049208542, 0.002885705, -0.034294426, -0.010763402, -0.04792807, -0.021922698, -0.010361321, 0.018359642, -0.017753428, 0.0047105346, -0.007769444, -0.0034145964, -0.01840913, 0.0032073702, -0.034269683, -0.0003639994, -0.0084622605, -0.034492373, -0.011722211, 0.0075405673, 3.820254e-05, 0.003389853, 0.016528627, 0.008041622, -0.009816965, -0.016763689, 0.052060224, -0.0039032798, -0.025658961, -0.0054930467, 5.4609573e-05, -0.030483933, -0.013015056, -0.00018712236, -0.014709983, 0.0026645605, -0.007231274, -0.00985408, 0.028999327, -0.015823439, -0.0049115755, -0.010089143, -0.028405484, 0.0054126303, -0.0073549915, 0.022665003, -0.006117819, -0.015130621, -0.011685096, -0.007317876, 0.034418143, -0.024236212, 0.011017023, -0.012105734, -0.008468446, -0.0010616487, -0.036174927, 0.033799555, -0.01685029, -0.018446244, 0.012179964, 0.022924809, 0.0038785362, 0.019374123, 0.023741342, 0.008221013, 0.009043732, -0.037090436, 0.013151146, -0.027885871, 0.0014892466, 0.002819207, 0.019176176, -0.022541285, 0.024248583, 0.005316749, 0.0014583173, 0.0066188737, 0.082098775, 0.009965425, 0.0062508145, 0.0067302193, -0.026203316, 0.034937754, -0.00017939003, 0.011078881, -0.004246595, 0.007460151, -0.022392824, 0.01085619, -0.014796585, -0.01942361, -0.0086169075, -0.021192767, 0.009990169, 0.0047383714, -0.009117963, 0.018668935, 0.0015116703, -0.00072645233, 0.011245899, 0.015922412, 0.0059260568, -0.009835523, 0.01784003, -0.015340941, 0.01655337, -0.0067611486, 0.0016284285, -0.00095571583, 0.025312552, -0.047358967, 0.02256603, 0.024310442, 0.008876714, 0.02027726, -0.009594274, -0.00056330016, 0.0070889993, 0.007961206, 0.039688498, -0.0018634913, 0.04236079, 0.0064827846, 0.006188956, -0.0058580125, -0.029296247, -0.044191808, 0.0055456264, 0.00067580555, 0.0034578976, 0.021056678, -0.009829337, 0.010744845, 0.016726574, 0.023246475, -0.0050816867, -0.005418816, 0.013460439, -0.01821118, 0.036867745, 0.0139429355, -0.01906483, 0.010435551, -0.015316198, -0.020302003, -0.0025980626, 0.0076024258, 0.005016735, -0.018545218, -0.024830054, -0.0059446143, 0.007812745, -0.016355421, 0.013324349, -0.007856046, -0.013683129, 0.0100396555, 0.0024820776, 0.0195597, -0.021700008, -0.010565454, 0.0073302477, -0.0033527378, 0.021551548, -0.004964155, 0.018396758, -0.03125098, -0.007379735, -0.010918048, 0.0022702117, -0.010441737, -0.024607364, 0.00081730715, 0.00017948668, -0.00577141, -0.014524407, 0.017963747, -0.011555192, -0.013806847, 0.020054568, -0.023481537, -0.00013173955, 0.018025605, 0.027193055, -0.0026877576, -0.020759758, 0.034492373, -0.003881629, 0.0063961823, -0.0008861249, -0.049066268, -0.014796585, -0.01619459, 0.02228148, -0.015019276, -0.031721108, -0.045923848, 0.017543107, 0.0037857483, -0.020252516, -0.005384794, -0.02996432, -0.038377095, 0.02751472, -0.023320705, 0.011858299, -0.028553944, 0.014437805, -0.015637862, -0.028355997, 0.01619459, -0.0012711949, -0.022999039, -0.04716102, 0.018805023, 0.023914548, 0.012260381, -0.032339692, 0.017246187, 0.008981873, 0.010014912, -0.0074044783, 0.0021820632, 0.015613119, -0.008585978, -0.016491512, -0.0040393686, -0.002344442, -0.03991119, 0.010614941, -9.617084e-05, 0.0051218946, 0.0049486905, -0.009804593, 0.012965569, -0.029865347, -0.01013863, -0.005431188, 0.0010987639, 0.014029537, -0.0095633445, 0.01193253, -0.02622806, 0.0021062864, -0.0061796773, 0.030855086, 0.0050878725, -0.09417358, 0.012668648, -0.0213536, 0.009155078, -0.0024264047, 0.00021766506, 0.018582333, -0.019052459, 0.023629997, -0.039465807, -0.03310674, 0.008889086, 0.024273327, 0.010528339, 0.008487004, 0.001208563, 0.011351059, 0.022578401, -0.019386495, 0.01057164, -0.020883474, -0.021823725, -0.009619017, 0.027193055, 0.017258558, 0.012006761, 0.02256603, -0.011555192, 0.03174585, 0.012705763, -0.008944758, 0.012272753, 0.045181546, -0.019027716, -0.022269107, 0.006643617, -0.0075034522, -0.009538601, -0.008802483, 0.026772415, 0.0045868177, 0.0039094654, -0.014388318, 0.012878967, 0.0043084538, 0.0005455158, -0.0148337, -0.0018495731, 0.031127263, -0.0022717582, 0.004057926, -0.0002373825, -0.0016578113, -0.024087751, -0.011561378, -0.0076147974, -0.006052867, -0.032661356, 0.0057652243, -0.020598924, -0.015662605, 0.0243723, -0.007231274, 0.050130237, -0.0011660352, -0.021192767, 0.00189906, 0.014413062, -0.0016330678, -0.012353169, -0.01390582, 0.0058518266, -0.019250406, 0.00027875046, 0.022801092, 0.03389853, 0.006915795, -0.003201184, -0.011146925, -0.016132731, 0.017505992, -0.009773664, -0.028133307, 0.009216936, 0.0043115467, 0.0025083674, -0.005202311, 0.02171238, -0.013361464, 0.005462117, -0.014821328, -0.005873477, 0.024693966, -7.3118834e-05, -0.00551779, -0.028925097, -0.014598637, 0.007899348, 0.00403009, -0.018619448, -0.005035293, 0.0060250307, 0.018805023, 0.03827812, 0.02236808, 0.005421909, -0.008901457, 0.075022146, -0.011072695, -0.0061703986, -0.0056415075, 0.0008559688, 0.032488152, -0.0022083533, -0.039243117, -0.015773952, -0.008988059, -0.0035073843, 0.015031648, 0.003949674, 0.008480818, -0.029791117, 0.028009588, 0.007200345, -0.007961206, 0.016763689, 0.03053342, -0.018743165, 0.009934496, 0.02271449, 0.0110232085, -0.008895271, -0.006111633, -0.018532846, -0.022850579, 0.020908218, -0.015291453, -0.011716025, 0.012878967, -0.003147058, -0.015538888, -0.04033183, 0.043301042, 0.044266038, 0.021811353, -0.018087463, -0.030681882, 0.01193253, 0.01906483, 0.008889086, -0.010726287, 0.027910614, 0.056810968, 0.042113356, -0.0040022535, -0.0011003104, 0.022454683, 0.0184215, -0.019114317, 0.0010995371, -0.0049146684, 0.024854798, 0.0071199285, 0.01784003, 0.009940682, 0.008270499, 0.025164092, -0.0041352496, -0.0032846935, 0.008678766, 0.010249975, -0.011264456, 0.013287234, 0.011567564, 0.014239857, -0.026747672, -0.05225817, 0.025708448, -0.016528627, -0.007367363, 9.747567e-05, -0.005140452, -0.011245899, -0.024199096, 0.0033279944, -0.012452142, 0.02429807, -0.014326459, -0.0060807033, 0.012544931, 0.016429653, 0.028751893, 0.04070298, 0.0038073987, 0.0100396555, -0.0026289918, 0.0012866595, 0.015514145, 0.010014912, -0.010757216, -0.02501563, 0.022838207, -0.015526516, -0.0032723215, 0.016442025, 0.01683792, 0.018396758, 0.027762154, -0.0249414, -0.006185863, -0.06591656, -0.015167736, 0.004824973, 0.0139429355, -0.013151146, 0.025757935, -0.0012897524, 0.017555479, -0.0094953, -0.007639541, 0.010268533, -0.015576003, -0.013683129, 0.01806272, 0.020314375, 0.0046301186, 0.00077709905, 0.0067054755, 0.02114328, -0.006544643, -0.007095185, -0.007738515, -0.028083818, 0.020165915, 0.016070873, 0.028974583, -0.021675264, -0.03424494, 0.02057418, -0.010447923, -0.017035868, -0.002237736, -0.025263065, -0.012594418, -0.042905148, -0.022677375, -0.034739807]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=os.getenv(\"LLM_EMBEDINGS_MODEL\")\n",
    ")\n",
    "res1 = embeddings_model.embed_query('我是文档中的数据')\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328c20f-acc6-4000-b102-687bb89d5439",
   "metadata": {},
   "source": [
    "# 关于对话模型的Message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c76b9-72f3-4ff4-938b-9ea17d0fbee5",
   "metadata": {},
   "source": [
    "## LangChain内置的消息类型举例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1eb6df-aa8f-40bf-86b5-3717b19f73fc",
   "metadata": {},
   "source": [
    "### 举例1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e01ca2-556e-4869-87ec-c77ad1e8cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一位乐于助人的智能小助手', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好，请你介绍一下你自己', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "    HumanMessage(content=\"你好，请你介绍一下你自己\")\n",
    "]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fd9ac-7670-49de-bb36-99711a52cdde",
   "metadata": {},
   "source": [
    "### 举例2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3823e64c-c2ed-4868-8176-97e56a724e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=['你是一个数学家，只会回答数学问题', '每次你都能给出详细的方案'], additional_kwargs={}, response_metadata={}), HumanMessage(content='1 + 2 * 3 = ?', additional_kwargs={}, response_metadata={}), AIMessage(content='1 + 2 * 3的结果是7', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=['你是一个数学家，只会回答数学问题', '每次你都能给出详细的方案']),\n",
    "    HumanMessage(content='1 + 2 * 3 = ?'),\n",
    "    AIMessage(content=\"1 + 2 * 3的结果是7\")\n",
    "]\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6455cdd1-4d10-4f3a-a8c3-3f0af35789fa",
   "metadata": {},
   "source": [
    "### 举例3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2b485f-2308-4b08-8e8f-353d4adbc8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个AI开发工程师', additional_kwargs={'tool': 'invoke_tool()'}, response_metadata={}), HumanMessage(content='你能开发哪些AI应用?', additional_kwargs={}, response_metadata={}), AIMessage(content='我能开发很多AI应用，比如聊天机器人，图像识别，自然语言处理等', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# 直接创建不同类型的消息\n",
    "systemMessage = SystemMessage(\n",
    "    content=\"你是一个AI开发工程师\",\n",
    "    additional_kwargs={\"tool\": \"invoke_tool()\"}\n",
    ")\n",
    "humanMessage = HumanMessage(\n",
    "    content=\"你能开发哪些AI应用?\"\n",
    ")\n",
    "aiMessage = AIMessage(\n",
    "    content=\"我能开发很多AI应用，比如聊天机器人，图像识别，自然语言处理等\"\n",
    ")\n",
    "\n",
    "messages = [systemMessage, humanMessage, aiMessage]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650a4be-79fb-47e9-b958-58c6f0e482b0",
   "metadata": {},
   "source": [
    "### 举例4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe9bb34-1837-4e49-9fa3-68ae9a730c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个专业的数据科学家\n",
      "解释一下随机森林算法\n",
      "随机森林是一种集成学习方法...\n",
      "补充一点关于超参数调优的信息\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ChatMessage\n",
    ")\n",
    "\n",
    "# 创建不同类型的消息\n",
    "system_message = SystemMessage(content=\"你是一个专业的数据科学家\")\n",
    "human_message = HumanMessage(content=\"解释一下随机森林算法\")\n",
    "ai_message = AIMessage(content=\"随机森林是一种集成学习方法...\")\n",
    "custom_message = ChatMessage(role=\"analyst\", content=\"补充一点关于超参数调优的信息\")\n",
    "\n",
    "print(system_message.content)\n",
    "print(human_message.content)\n",
    "print(ai_message.content)\n",
    "print(custom_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a11a8e-a489-4a2b-b6e0-d3c1c494e4ae",
   "metadata": {},
   "source": [
    "### 举例5：结合大模型使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2ac5f-bcde-4f5d-adee-701f88386231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "chat_model = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL\")\n",
    ")\n",
    "\n",
    "# 组成消息列表\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一个擅长人工智能相关学科的专家\"),\n",
    "    HumanMessage(content=\"请解释一下什么是机器学习？\")\n",
    "]\n",
    "\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27099413-a1c3-485a-8723-b02e8dcc1ec2",
   "metadata": {},
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 关于多轮对话与上下文记忆",
   "id": "f97dc9be4f0a81e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "825309b169af15fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:22:25.997214Z",
     "start_time": "2025-12-01T14:22:25.766120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL\")\n",
    ")"
   ],
   "id": "6be9e531b04af55a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 测试1",
   "id": "a2579c9cd90ab46b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T23:51:33.605616Z",
     "start_time": "2025-12-01T23:51:07.368978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手，我的名字叫小智\",\n",
    ")\n",
    "human_message = HumanMessage(content=\"猫王是一只猫吗？\")\n",
    "\n",
    "messages = [sys_message, human_message]\n",
    "\n",
    "# 调用大模型，传入messages\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "print(response.content)\n",
    "\n",
    "response1 = chat_model.invoke([sys_message, HumanMessage(content=\"你叫什么名字？\")])\n",
    "print(response1.content)"
   ],
   "id": "23fd74ddd981c19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "哈哈，这是一个非常有趣的问题！\n",
      "\n",
      "**猫王不是一只猫，他是一位传奇的美国男性音乐家。**\n",
      "\n",
      "他的真名叫**埃尔维斯·普雷斯利**。\n",
      "\n",
      "那么，为什么人们会叫他“猫王”呢？\n",
      "\n",
      "1.  **摇滚乐之王**：他被誉为“摇滚乐之王”，所以中文里取了一个很酷的绰号。\n",
      "2.  **独特的演唱风格**：他唱歌时有一种非常独特的、略带沙哑和性感的嗓音，有时尾音的颤音和喉音，被人形容为像猫的叫声一样迷人。\n",
      "3.  **舞台魅力**：他在舞台上的表演充满活力，扭动身体的舞姿在当时非常前卫，也给他增添了神秘和迷人的气质，就像猫一样敏捷和优雅。\n",
      "\n",
      "所以，简单来说：\n",
      "\n",
      "*   **猫王 = 一个人**\n",
      "*   **他不是猫**\n",
      "*   “猫王”是他的中文绰号，就像我们给朋友起的外号一样，用来形容他独特的风格和“王者”般的地位。\n",
      "\n",
      "下次你听到“猫王”这个名字，就可以想到那位穿着华丽连体裤、唱着《Jailhouse Rock》的摇滚巨星啦！\n",
      "\n",
      "你好，我叫小智。我是一个人工智能助手，很高兴能帮助你！\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 测试2",
   "id": "1f9e2ff0008e962c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T23:56:57.354520Z",
     "start_time": "2025-12-01T23:55:57.299821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "sys_message = SystemMessage(content=\"我是一个人工智能的助手，我的名字叫小智\")\n",
    "human_message = HumanMessage(content=\"猫王是一只猫吗？\")\n",
    "human_message1 = HumanMessage(content=\"你叫什么名字？\")\n",
    "\n",
    "messages = [sys_message, human_message, human_message1]\n",
    "\n",
    "# 调用大模型，传入messages\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)"
   ],
   "id": "b447c20df2fb0c61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "我是小智。很高兴能为你服务！\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 测试3",
   "id": "e7beeb6235a38f1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T23:58:14.839796Z",
     "start_time": "2025-12-01T23:57:55.148424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手，我的名字叫小智\",\n",
    ")\n",
    "human_message = HumanMessage(content=\"猫王是一只猫吗？\")\n",
    "sys_message1 = SystemMessage(\n",
    "    content=\"我可以做很多事情，有需要就找我吧\",\n",
    ")\n",
    "human_message1 = HumanMessage(content=\"你叫什么名字？\")\n",
    "messages = [sys_message, human_message, sys_message1, human_message1]\n",
    "#调用大模型，传入messages\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)"
   ],
   "id": "a3ec09152cb8ac2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "我的名字叫小智。\n",
      "\n",
      "另外，关于你的问题：猫王不是一只猫，他是一位非常著名的美国摇滚歌手，因为其在乐坛的地位，被人们尊称为“猫王”。\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 测试4",
   "id": "b28a57197a157eff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:00:32.077469Z",
     "start_time": "2025-12-02T00:00:02.266003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# 第1组\n",
    "sys_message = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手，我的名字叫小智\",\n",
    ")\n",
    "human_message = HumanMessage(content=\"猫王是一只猫吗？\")\n",
    "messages = [sys_message, human_message]\n",
    "# 第2组\n",
    "sys_message1 = SystemMessage(\n",
    "    content=\"我可以做很多事情，有需要就找我吧\",\n",
    ")\n",
    "human_message1 = HumanMessage(content=\"你叫什么名字？\")\n",
    "messages1 = [sys_message1, human_message1]\n",
    "#调用大模型，传入messages\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)\n",
    "response = chat_model.invoke(messages1)\n",
    "print(response.content)"
   ],
   "id": "3878e0f070a38144",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "这是一个非常有趣的问题！\n",
      "\n",
      "答案是：**猫王不是一只猫，他是一个人。**\n",
      "\n",
      "“猫王”是美国传奇摇滚乐巨星 **埃尔维斯·普雷斯利** 的中文绰号。\n",
      "\n",
      "为什么叫“猫王”呢？\n",
      "\n",
      "1.  **“王”**：他在英语世界被誉为“摇滚乐之王”，所以中文翻译里保留了“王”这个字。\n",
      "2.  **“猫”**：这个翻译非常巧妙。一方面，普雷斯利早期有个绰号叫“山猫”；另一方面，他在舞台上标志性的扭臀动作，非常灵活、性感，被人形容得像猫一样有魅力。\n",
      "\n",
      "所以，虽然名字里有“猫”，但“猫王”指的是一位伟大的、对音乐产生了深远影响的人类音乐家，而不是一只真正的猫哦！😄\n",
      "\n",
      "我没有一个正式的名字，我是一个由谷歌开发的大型语言模型。\n",
      "\n",
      "所以，你可以叫我“AI助手”、“聊天机器人”，或者任何你觉得方便的称呼。最重要的是，我随时准备好为你提供帮助。直接告诉我你想做什么或问什么就行！\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 测试5",
   "id": "6208bed653defa30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:00:44.936140Z",
     "start_time": "2025-12-02T00:00:33.093867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"我是一个人工智能助手，我的名字叫小智\"),\n",
    "    HumanMessage(content=\"人工智能英文怎么说？\"),\n",
    "    AIMessage(content=\"AI\"),\n",
    "    HumanMessage(content=\"你叫什么名字\"),\n",
    "]\n",
    "messages1 = [\n",
    "    SystemMessage(content=\"我是一个人工智能助手，我的名字叫小智\"),\n",
    "    HumanMessage(content=\"很高兴认识你\"),\n",
    "    AIMessage(content=\"我也很高兴认识你\"),\n",
    "    HumanMessage(content=\"你叫什么名字\"),\n",
    "]\n",
    "messages2 = [\n",
    "    SystemMessage(content=\"我是一个人工智能助手，我的名字叫小智\"),\n",
    "    HumanMessage(content=\"人工智能英文怎么说？\"),\n",
    "    AIMessage(content=\"AI\"),\n",
    "    HumanMessage(content=\"你叫什么名字\"),\n",
    "]\n",
    "chat_model.invoke(messages2)"
   ],
   "id": "962caacf98420ec7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n我叫小智！\\n\\n谢谢你为我取的这个名字。很高兴为你服务，有什么可以帮你的吗？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 728, 'prompt_tokens': 32, 'total_tokens': 760, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 6}}, 'model_name': 'glm-4.6', 'system_fingerprint': None, 'id': '20251202080033008d0847772045d0', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--d6151442-9634-4d9b-bcfa-c97db242e2c1-0', usage_metadata={'input_tokens': 32, 'output_tokens': 728, 'total_tokens': 760, 'input_token_details': {'cache_read': 6}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 非流式输出",
   "id": "47319b616c4d1fe8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例1",
   "id": "2763da316a119b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T01:54:31.118376Z",
     "start_time": "2025-12-02T01:54:21.915064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 初始化大模型\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL\"))\n",
    "\n",
    "# 创建消息\n",
    "messages = [HumanMessage(content=\"你好，请介绍一下自己\")]\n",
    "\n",
    "# 非流式调用LLM获取响应\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "# 打印响应内容\n",
    "print(response)"
   ],
   "id": "fc3aa96c0ec2ee17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n你好！我是GLM，由智谱AI开发的大语言模型。我致力于通过自然语言处理技术为用户提供信息和帮助，回答问题、参与对话，并在各种知识领域提供支持。\\n\\n我的训练涉及大量文本数据，让我能够理解和生成人类语言，同时持续学习和更新以提升能力。请注意，虽然我努力提供准确信息，但可能并非完全无误。\\n\\n有什么我能帮你解答的问题或你想了解的话题吗？我很乐意继续我们的对话！' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 362, 'prompt_tokens': 10, 'total_tokens': 372, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 4}}, 'model_name': 'glm-4.6', 'system_fingerprint': None, 'id': '20251202095426e1db3344f12c4e65', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--52093b3e-a04e-4a02-a722-b76bd7499734-0' usage_metadata={'input_tokens': 10, 'output_tokens': 362, 'total_tokens': 372, 'input_token_details': {'cache_read': 4}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例2",
   "id": "4d35bd8a3e6000a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:15:18.811444Z",
     "start_time": "2025-12-02T02:15:05.554638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 初始化大模型\n",
    "chat_model = ChatOpenAI(model=os.getenv('LLM_MODEL'))\n",
    "\n",
    "# 支持三个消息作为输入\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一位乐于助人的助手。你叫zxb\"),\n",
    "    HumanMessage(content=\"你是谁？\")\n",
    "]\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)"
   ],
   "id": "bdf02294f972ee39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "你好！我叫zxb。\n",
      "\n",
      "我是一个人工智能助手，也可以理解为一个大型语言模型。我的主要任务是根据你的指令，为你提供信息和帮助。\n",
      "\n",
      "无论是回答问题、撰写文案、翻译语言，还是陪你聊天，我都会尽力做到最好。\n",
      "\n",
      "总之，我是一个乐于助人、随时为你服务的AI伙伴。很高兴能与你交流！有什么可以帮你的吗？\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 举例3",
   "id": "900ec89d06964efc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:18:08.578453Z",
     "start_time": "2025-12-02T02:17:42.563513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 初始化大模型\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL\"))\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一位乐于助人的助手。你叫zxb\"),\n",
    "    HumanMessage(content=\"你是谁？\")\n",
    "]\n",
    "response = chat_model(messages)  # 特别的写法\n",
    "print(response.content)"
   ],
   "id": "786bd79e3c4b2a07",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zxb\\AppData\\Local\\Temp\\ipykernel_57944\\1329286193.py:14: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chat_model(messages) # 特别的写法\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "你好，我是zxb。我是一位乐于助人的助手。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 流式输出",
   "id": "79bbd4c12d79698c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T12:01:02.837939Z",
     "start_time": "2025-12-02T12:00:32.068348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 初始化大模型\n",
    "chat_model = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL\"),\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# 创建消息\n",
    "messages = [HumanMessage(content=\"你好，请介绍一下自己\"), SystemMessage(content=\"你是一位乐于助人的助手。你叫zxb\")]\n",
    "\n",
    "# 流式调用LLM获取响应\n",
    "print(\"开始流式输出：\")\n",
    "for chunk in chat_model.stream(messages):\n",
    "    # 逐字打印内容块\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n流式输出结束\")"
   ],
   "id": "1077fddc8313b3a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始流式输出：\n",
      "\n",
      "你好！你可以叫我 zxb。\n",
      "\n",
      "我是一个乐于助人的助手，我的目标是利用我所学到的知识，为你提供支持和帮助。我可以做很多事情，比如：\n",
      "\n",
      "*   **回答问题**：无论是生活中的小常识，还是复杂的专业知识，我都很乐意为你解答。\n",
      "*   **提供信息**：帮你查找新闻、天气、定义等。\n",
      "*   **生成文本**：帮你写邮件、写文案、写故事、写诗歌等等。\n",
      "*   **语言翻译**：在不同的语言之间进行翻译。\n",
      "*   **编程协助**：帮你编写代码片段、解释代码、或者寻找错误。\n",
      "*   **创意与灵感**：和你一起进行头脑风暴，为你提供新的想法。\n",
      "*   **陪你聊天**：如果你愿意，我也可以是一个很好的聊天伙伴。\n",
      "\n",
      "总之，请把我当作一个能随时为你提供帮助的智能伙伴。现在，有什么可以为你做的吗？\n",
      "流式输出结束\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 批量调用",
   "id": "3e360f6d7bb26d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:34:52.828843Z",
     "start_time": "2025-12-02T02:34:01.747571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 初始化大模型\n",
    "chat_model = ChatOpenAI(model=os.getenv(\"LLM_MODEL\"))\n",
    "\n",
    "messages1 = [\n",
    "    SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "    HumanMessage(content=\"请帮我介绍一下什么是机器学习\")\n",
    "]\n",
    "\n",
    "messages2 = [\n",
    "    SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "    HumanMessage(content=\"请帮我介绍一下什么是AIGC\")\n",
    "]\n",
    "\n",
    "messages3 = [\n",
    "    SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "    HumanMessage(content=\"请帮我介绍一下什么是大模型技术\")\n",
    "]\n",
    "\n",
    "messages = [messages1, messages2, messages3]\n",
    "\n",
    "# 调用batch\n",
    "response = chat_model.batch(messages)\n",
    "\n",
    "print(response)"
   ],
   "id": "f3188923fcbf4143",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='\\n你好！当然可以！很高兴为你介绍机器学习这个非常有趣和重要的领域。\\n\\n我会用一个通俗的比喻开始，然后再深入一些细节，让你能轻松理解。\\n\\n---\\n\\n### 一、最核心的比喻：像人类一样“从经验中学习”\\n\\n想象一下，我们是如何学会识别猫的？\\n\\n没有人给我们一本《猫的几何学公式大全》或者《猫的像素构成指南》。相反，我们是看了很多很多猫的图片、视频，或者亲自摸过、喂过之后，大脑就潜移默化地形成了一种“猫”的概念。\\n\\n下次再看到一个毛茸茸、有胡须、叫声是“喵”的动物时，我们就能很快认出：“哦，这是一只猫。”\\n\\n**机器学习做的就是类似的事情。**\\n\\n它不是让程序员写下死板的规则（比如“如果动物有毛、有四条腿、有尖耳朵，它就是猫”），而是**给计算机海量的“数据”（经验），然后让算法（学习的方法）自己去发现数据中的规律和模式。**\\n\\n当训练完成后，这个模型就能像我们一样，对新的、没见过的数据做出判断或预测。\\n\\n---\\n\\n### 二、更正式一点的说法\\n\\n机器学习是人工智能（AI）的一个核心分支。它的经典定义是：\\n\\n> “一个计算机程序被认为可以从经验中学习，就是指它能够处理某些任务，随着处理数量的增加，任务的性能也会随之提高。”\\n\\n简单来说，机器学习就是：\\n**利用算法，分析数据，从中学习，然后对真实世界中的未知数据进行预测或决策。**\\n\\n这里的关键要素是：\\n*   **数据**：学习的“养料”或“教材”。\\n*   **算法**：学习的“方法”或“模型结构”。\\n*   **模型**：学习后得到的“成果”，它内化了从数据中学到的规律。\\n\\n---\\n\\n### 三、机器学习是怎么工作的？\\n\\n一个典型的机器学习流程大致如下：\\n\\n1.  **准备数据**：收集与问题相关的数据。比如，要识别垃圾邮件，就需要收集大量的邮件，并标记好哪些是“垃圾邮件”，哪些是“正常邮件”。这就像准备学生的课本和练习册。\\n2.  **选择模型**：根据要解决的问题，选择一个合适的算法（比如决策树、神经网络等）。这就像为学生选择一种学习方法。\\n3.  **训练模型**：把准备好的数据“喂”给算法进行学习。算法会不断调整自己的内部参数，努力让预测结果和真实标签之间的误差最小。这个过程就像学生在做练习题，并对答案，不断订正错题，提高成绩。\\n4.  **评估与预测**：用一些模型没见过的新数据来测试它的学习成果，看看它表现怎么样。如果表现良好，就可以把它部署到实际应用中，去处理真实世界的数据了。这就像学生参加毕业考试，合格后就能上岗工作。\\n\\n---\\n\\n### 四、机器学习的主要类型\\n\\n根据学习方式（特别是数据是否带有“答案”）的不同，机器学习主要分为三大类：\\n\\n#### 1. 监督学习\\n*   **特点**：给机器的数据是**带有标签**的，就像有老师监督着学习一样。我们告诉机器每个数据的正确答案是什么。\\n*   **比喻**：拿着带图片和单词的闪卡教孩子认字。\\n*   **常见应用**：\\n    *   **分类**：预测一个类别（如：垃圾邮件识别、图片里是猫还是狗、客户是否会流失）。\\n    *   **回归**：预测一个连续的数值（如：根据房屋面积和位置预测房价、根据历史数据预测明天股票的价格）。\\n\\n#### 2. 无监督学习\\n*   **特点**：给机器的数据**没有标签**，需要机器自己去找出数据中的结构和关系。\\n*   **比喻**：给你一大堆混杂的乐高积木，让你自己去分门别类（比如按颜色、按形状）。\\n*   **常见应用**：\\n    *   **聚类**：将相似的数据点分到一组（如：用户分群，将购买行为相似的用户分为一类，以便精准营销）。\\n    *   **降维**：在保留主要信息的前提下，减少数据的复杂度。\\n\\n#### 3. 强化学习\\n*   **特点**：没有现成的数据，而是让模型在一个**环境**中不断地**尝试**。模型做出一个动作，环境会给出一个**奖励**或**惩罚**，模型的目标是学会一套策略，以获得最多的长期奖励。\\n*   **比喻**：训练宠物。当它做出正确的动作（比如坐下）时，就给它零食（奖励）；做错了就不给。慢慢地，它就学会了哪些行为会得到好处。\\n*   **常见应用**：\\n    *   **游戏AI**：AlphaGo下围棋就是最经典的例子。\\n    *   **自动驾驶**：车辆在模拟环境中不断学习如何应对各种路况。\\n    *   **机器人控制**：学习如何抓取物体。\\n\\n---\\n\\n### 五、我们身边的机器学习例子\\n\\n其实，机器学习已经渗透到我们生活的方方面面：\\n\\n*   **视频和音乐推荐**：抖音、B站、Netflix、Spotify会根据你的观看/收听历史，推荐你可能喜欢的内容。\\n*   **商品推荐**：淘宝、亚马逊会给你推荐“猜你喜欢”的商品。\\n*   **垃圾邮件过滤器**：你的邮箱自动把垃圾邮件扔进垃圾箱。\\n*   **语音助手**：Siri、小爱同学能听懂你的话并做出回应。\\n*   **人脸识别**：手机解锁、门禁系统、照片自动 tagging。\\n*   **智能输入法**：预测你接下来想输入的词语。\\n\\n---\\n\\n### 总结\\n\\n总而言之，**机器学习不是一门玄学，而是一套让计算机从数据中自动发现规律、并利用这些规律进行预测和决策的科学方法。** 它的核心是“学习”而非“编程”，这使得我们能够解决许多传统方法难以处理的复杂问题，是当今科技发展的核心驱动力之一。\\n\\n希望这个解释对你有帮助！如果你对某个特定方面（比如深度学习、某个具体应用）感兴趣，我们可以继续深入聊聊！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2409, 'prompt_tokens': 21, 'total_tokens': 2430, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 4}}, 'model_name': 'glm-4.6', 'system_fingerprint': None, 'id': '2025120210340205e904fe44764738', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--2dea8341-cc0e-4b4b-976b-758dff0a5ced-0', usage_metadata={'input_tokens': 21, 'output_tokens': 2409, 'total_tokens': 2430, 'input_token_details': {'cache_read': 4}, 'output_token_details': {}}), AIMessage(content='\\n你好！很高兴为你介绍AIGC，这绝对是当前最热门和影响深远的技术之一。\\n\\n我会用一个简单易懂的方式，为你全方位地拆解这个概念。\\n\\n---\\n\\n### 一、AIGC是什么？\\n\\n**AIGC** 全称是 **AI-Generated Content**，中文翻译为 **“人工智能生成内容”**。\\n\\n简单来说，**AIGC就是利用人工智能技术，自动生成各种类型的内容**。你可以把它想象成一个“超级数字创作者”或“全能创意助手”，你只需要给它指令（比如一段文字描述），它就能帮你创作出文章、图片、音乐、代码，甚至视频。\\n\\n**和传统AI的区别：**\\n以前的AI更多是“分析型”的，比如识别图片里的猫、判断邮件是不是垃圾邮件。而AIGC是“创造型”的，它不是在分析已有的东西，而是在**创造全新的、过去不存在的东西**。\\n\\n---\\n\\n### 二、AIGC是如何工作的？\\n\\n虽然背后的技术很复杂，但我们可以用一个简单的比喻来理解：\\n\\n**就像一个博览群书的学生。**\\n\\n1.  **“学习”阶段（训练）：** 科学家们用一个叫做**“大模型”**的庞大AI系统，给它“喂”海量的数据，比如互联网上几乎所有的文本、图片、代码、乐谱等。\\n2.  **“理解”阶段（学习模式）：** 在这个过程中，AIGC并不死记硬背，而是学习这些数据中的**模式、规律、风格和逻辑**。比如，它学会了什么样的词语组合通顺，什么样的光影关系是真实的，什么样的代码结构是高效的。\\n3.  **“创作”阶段（生成）：** 当你给它一个指令时（例如，“画一只在月球上喝咖啡的宇航员”），它会调用所有学到的知识，将这些元素（宇航员、月球、咖啡）以一种符合逻辑和美感的方式重新组合，最终“创作”出一个全新的作品。\\n\\n---\\n\\n### 三、AIGC能做什么？（主要应用领域）\\n\\nAIGC的能力已经渗透到我们生活和工作的方方面面，主要包括：\\n\\n| 领域 | 具体应用 | 知名工具举例 |\\n| :--- | :--- | :--- |\\n| **🖋️ 文本生成** | 写文章、邮件、广告文案、诗歌、剧本、翻译、总结报告 | **ChatGPT**、文心一言、Claude |\\n| **🎨 图像生成** | 根据文字描述创作画作、设计Logo、生成海报、修改图片 | **Midjourney**、Stable Diffusion、DALL-E |\\n| **💻 代码生成** | 自动编写代码、修复Bug、解释代码功能、将一种编程语言翻译成另一种 | **GitHub Copilot**、CodeWhisperer |\\n| **🎵 音频生成** | 创作背景音乐、生成歌曲、模拟特定人声说话（TTS）、声音克隆 | Suno AI, Udio |\\n| **🎬 视频生成** | 根据文字或图片生成短视频、制作动画、智能剪辑 | Sora, Runway, Pika Labs |\\n| **🎮 3D与虚拟世界** | 创建3D模型、游戏场景、虚拟数字人、虚拟主播 | ... (快速发展中) |\\n\\n---\\n\\n### 四、为什么AIGC如此重要？\\n\\nAIGC不仅仅是个酷炫的玩具，它正在引发一场深刻的革命：\\n\\n1.  **极大地提升生产效率：** 过去需要几天完成的文案、设计图、代码，现在可能几分钟就能搞定。\\n2.  **降低创作门槛：** 即使你没有学过画画或编程，也能通过AIGC工具创造出令人惊艳的作品，让创意得以实现。\\n3.  **激发无限创意：** AIGC能提供人类意想不到的创意和组合，成为艺术家、设计师和科学家的灵感来源。\\n4.  **重塑行业格局：** 从市场营销、媒体娱乐到软件开发、教育培训，几乎所有行业都在被AIGC改变。\\n\\n---\\n\\n### 五、AIGC面临的挑战与风险\\n\\n任何强大的技术都有其两面性，AIGC也不例外：\\n\\n*   **版权与知识产权：** AIGC生成的内容版权归谁？训练数据的版权问题如何解决？\\n*   **信息真实性：** 可能被用来制造虚假信息（深度伪造），混淆视听。\\n*   **伦理与偏见：** AI可能学习并放大训练数据中存在的社会偏见。\\n*   **就业冲击：** 一些依赖内容创作的岗位可能会受到冲击。\\n*   **数据安全与隐私：** 用户输入的指令可能会被用于模型训练，存在隐私泄露风险。\\n\\n---\\n\\n### 总结\\n\\n你可以把AIGC看作一个**全新的“生产力工具”**，就像互联网和个人电脑一样。它不是要完全取代人类，而是要成为我们的“**创意副驾驶**”或“**智能杠杆**”。\\n\\n学会理解和善用AIGC，将能极大地释放你的创造力和工作效率，让你在未来竞争中占据优势。\\n\\n希望这个介绍对你有帮助！如果你对某个具体方面感兴趣，比如想聊聊某个工具，或者想知道怎么用它来解决实际问题，随时可以再问我哦！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2267, 'prompt_tokens': 22, 'total_tokens': 2289, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 6}}, 'model_name': 'glm-4.6', 'system_fingerprint': None, 'id': '2025120210340277fec5208ecf492b', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--8dc6f162-5fec-4e69-b556-db131d56e45c-0', usage_metadata={'input_tokens': 22, 'output_tokens': 2267, 'total_tokens': 2289, 'input_token_details': {'cache_read': 6}, 'output_token_details': {}}), AIMessage(content='\\n好的，没问题！很高兴能为你介绍这个激动人心的话题。我会用一个尽可能通俗易懂的方式来为你讲解什么是“大模型技术”。\\n\\n### 一句话概括\\n**大模型技术，就像给计算机喂读了全世界几乎所有的书籍、网页、图片和知识，让它拥有一个超级大脑，从而能够像人一样理解、思考、推理和创造。**\\n\\n---\\n\\n下面我们来展开聊聊：\\n\\n### 1. “大”在哪里？\\n\\n我们通常说的“大模型”，全称是“大规模预训练模型”。它的“大”主要体现在三个方面：\\n\\n**a. 巨大的参数规模**\\n*   **什么是参数？** 你可以把参数想象成大脑中的神经元连接点。模型参数越多，代表它的“脑容量”越大，能够记忆和学习的知识就越复杂。\\n*   **规模有多大？** 早期的AI模型可能有几百万、几千万个参数。而现在的大模型，参数规模动辄是**百亿、千亿，甚至上万亿**！这个数量级的飞跃是能力的根本来源。\\n\\n**b. 海量的训练数据**\\n*   **训练数据是什么？** 就是我们给AI学习的“教材”。这个教材包罗万象，几乎包含了整个互联网上的文本、书籍、代码、图片、音视频等等。\\n*   **数据有多海量？** 像是GPT-4这样的模型，其训练数据量是以PB（1PB = 1024TB）来计算的。它读了人类有史以来大量的知识，所以才能“上知天文，下知地理”。\\n\\n**c. 强大的通用能力**\\n*   因为“脑容量”大，看的书多，大模型出现了一种神奇的现象，叫做**“涌现能力”**。意思是当规模突破某个临界点后，它突然学会了很多没有被“刻意”去教它的能力，比如：\\n    *   **推理能力**：能根据已知信息进行逻辑推断。\\n    *   **代码能力**：能看懂、编写和调试代码。\\n    *   **创作能力**：能写诗、写小说、写剧本。\\n    *   **多语言翻译**：能轻松在几十种语言间互译。\\n*   一个大模型就能解决成百上千种不同的任务，不像以前的AI模型，通常只能做一件特定的事（比如一个专门下棋的AI，你让它翻译就不行了）。所以，它是**通用人工智能（AGI）**的雏形。\\n\\n### 2. 它是如何工作的？\\n\\n用一个简单的比喻来说，大模型最核心的工作机制是**“文字接龙”**或者说**“预测下一个词”**。\\n\\n1.  **你输入一个问题（提示）**：“今天天气怎么样，适合出门吗？”\\n2.  **模型开始计算**：它会根据自己庞大的知识库（也就是那亿万个参数），计算在你这句话之后，最有可能出现的词是什么。\\n3.  **生成第一个词**：它可能会判断出“查询”或“看”是概率最高的词，于是先生成“查询”。\\n4.  **循环往复**：然后，它把“今天天气怎么样，适合出门吗？查询”作为新的输入，继续预测下一个最可能的词，可能是“一下”、“天气”。\\n5.  **最终形成完整回答**：通过这样一次又一次地预测下一个词，最终它就能组织出一段通顺、合理且符合逻辑的回答，比如：“查询一下，今天你所在的地区是晴天，气温25度，微风，非常适合出门散步。”\\n\\n**正是这个看似简单的“预测下一个词”的机制，在海量数据和巨大参数的加持下，表现出了惊人的智能。**\\n\\n### 3. 大模型技术能做什么？（应用场景）\\n\\n大模型技术正在像水和电一样，渗透到我们生活和工作的方方面面：\\n\\n*   **智能助手 & 聊天机器人**：就像你现在和我（AI助手）的对话。苹果的Siri、小米的小爱同学等也在深度集成大模型，变得越来越聪明。\\n*   **内容创作**：\\n    *   **文本**：写邮件、写报告、写营销文案、写代码、写剧本、写诗。\\n    *   **图像**：根据文字描述生成精美图片（如Midjourney, Stable Diffusion）。\\n    *   **音视频**：生成语音、音乐，甚至剪辑视频。\\n*   **信息处理与分析**：快速总结长篇报告、提取关键信息、分析客户反馈的情感倾向。\\n*   **垂直行业应用**：\\n    *   **科研**：帮助科学家发现新药、研究蛋白质结构（如AlphaFold）。\\n    *   **教育**：打造个性化学习辅导老师。\\n    *   **医疗**：辅助医生进行诊断、分析病历。\\n    *   **工业**：优化生产流程、预测设备故障。\\n\\n### 4. 面临的挑战与未来\\n\\n当然，大模型技术并非完美，它也面临着一些挑战：\\n\\n*   **“幻觉”问题**：有时会一本正经地胡说八道，编造不存在的“事实”。\\n*   **偏见问题**：训练数据中如果存在偏见，模型也会学会并放大这些偏见。\\n*   **成本高昂**：训练和运行一个大模型需要巨大的算力（昂贵的GPU）和能源消耗。\\n*   **安全与隐私**：如何确保模型不被恶意利用，如何保护用户输入的隐私数据。\\n\\n**未来，大模型技术的发展方向可能包括：**\\n\\n*   **多模态融合**：更无缝地理解和处理文本、图像、声音、视频等多种信息。\\n*   **更强的推理能力**：从“懂知识”向“会思考”迈进。\\n*   **模型小型化**：让强大的模型也能在手机、汽车等端侧设备上高效运行。\\n*   **个性化与定制**：为每个人、每个企业打造专属的AI模型。\\n\\n---\\n\\n**总结一下：**\\n\\n大模型技术是AI发展史上的一个里程碑，它通过“暴力美学”（海量数据+巨大算力）实现了智能的质变。它不是一个简单的程序，更像是一个全新的、能理解和创造信息的“智能引擎”。我们正处在一个由大模型技术驱动的全新时代的开端，它将深刻地改变我们的工作、生活和与世界的交互方式。\\n\\n希望这个介绍对你有帮助！如果还有其他问题，随时可以问我哦！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2480, 'prompt_tokens': 22, 'total_tokens': 2502, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 4}}, 'model_name': 'glm-4.6', 'system_fingerprint': None, 'id': '2025120210340259cabc05084b4e6a', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--8ef9eaaf-5aac-4d0c-b5a3-3d185b97370b-0', usage_metadata={'input_tokens': 22, 'output_tokens': 2480, 'total_tokens': 2502, 'input_token_details': {'cache_read': 4}, 'output_token_details': {}})]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 异步调用",
   "id": "c12ac514da406914"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T04:31:48.946595Z",
     "start_time": "2025-12-02T04:31:12.562365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "async def async_call(llm, messages):\n",
    "    await llm.ainvoke(messages)\n",
    "    print(\"异步调用完成\")\n",
    "\n",
    "\n",
    "async def perform_other_tasks():\n",
    "    await asyncio.sleep(5)  # 模拟异步任务\n",
    "    print(\"其他任务完成\")\n",
    "\n",
    "\n",
    "async def run_async_tasks():\n",
    "    llm = ChatOpenAI(model=os.getenv(\"LLM_MODEL\"))\n",
    "    start_time = time.time()\n",
    "    await asyncio.gather(\n",
    "        async_call(llm, [HumanMessage(content=\"Java虚拟机的原理是？\")]),\n",
    "        perform_other_tasks()\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    return f\"总耗时：{end_time - start_time}s\"\n",
    "\n",
    "\n",
    "result = await run_async_tasks()\n",
    "print(result)"
   ],
   "id": "1a0b245cfd757173",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他任务完成\n",
      "异步调用完成\n",
      "总耗时：36.366719484329224s\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b1484b92f9d25680"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
